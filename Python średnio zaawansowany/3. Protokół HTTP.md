### 3.1 HTML
Punktem wyjścia do zrozumienia wielu tematów związanych z wykorzystaniem protokołu HTTP (*HyperText Transfer Protocol*) jest podstawowa znajomość języka HTML (*HyperText Markup Language*). Szczególnie istotne jest to podczas web scrapingu, czyli procesu pozyskiwania danych znajdujących się na stronach www.

HTML to język znaczników, który definiuje zawartość strony internetowej. W różnych znacznikach – zwanych również "tagami" – znajdują się poszczególne elementy widoczne na stronie, takie jak np. paragrafy tekstu, linki, tabele, nagłówki itd. Poniżej zamieszczony został przykładowy kod HTML, który opisuje strukturę bardzo prostej strony internetowej. Właściwa zawartość strony (to, co widzimy w przeglądarce) znajduje się wewnątrz znacznika `<body> </body>`. Są w nim zagnieżdżone kolejne tagi – w tym przypadku jeden: `<div> </div>`. Cała reszta to metadane.

```html
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>My test page</title>
  </head>
  
  <body>
      <div>Hello world</div>
  </body>
</html>
```

Wszystko, co znajduje się pomiędzy symbolami `<...>` a `</...>` stanowi zawartość danego znacznika. Może być tam umieszczony tekst lub głębiej zagnieżdżone tagi. Struktura takich zagnieżdżeń może być bardzo złożona.

Poniżej znajduje się opis kilku najczęściej spotykanych znaczników HTMLa. 

### Naglówek

Nagłówek artykułu czy podtytuł nad paragrafem to przykładowe sytuacje, gdzie znajduje zastosowanie ten znacznik. Nagłówki często ułożone są w hierarchii – tak jak na tej stronie.

```html
<h1>Nagłówek pierwszego rzędu</h1>

<h2>Nagłówek drugiego rzędu</h2>

...

<h6>Nagłówek szóśtego rzędu</h6>
```

### Link

Znacznik `<a>` tworzy hiperłącza, które kierują nas na inne strony www lub nasze własne podstrony. Przykłady zastosowań to tworzenie linków do innych witryn, nawigacja w obrębie strony oraz otwieranie linków w nowych oknach przeglądarki.

```html
<a href='https://example.org'>Tekst hiperłącza</a>

<a href='subpage/index.html'>Tekst hiperłącza</a>
```


### Paragraf

Dłuższy kawałek tekstu przechowujemy zwykle w paragrafie.

```html
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit,
sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
```

### Lista 

Jeśli na stronie znajduje się wiele podobnie wyglądająych elementów, prawdopodobnie należą one do jednej listy. Lista może być uporządkowana (***o**rdered **l**ist*) lub nieuporządkowana (***u**nordered **l**ist*). Elementy tej pierwszej często są ponumerowane.

Lista składa się z ***l**ist **i**temów*.

```html
<ul> 
    <li>Element 1</li>
    <li>Element 2</li>
    <li>Element 3</li>
</ul>


<ol> 
    <li>Element 1</li>
    <li>Element 2</li>
    <li>Element 3</li>
</ol>
```


### Div

Div to uniwersalny znacznik, który nie ma jednego, szczególnego zastosowania. Może być kontenerem, wewnątrz którego znajdą się kolejne tagi.

```html
<div> Div </div>


<div> 
    <div>1</div>
    <div>2</div>
    <div>3</div>
</div>
```

---

Aby sprawdzić, jak na stronie www będzie wyglądał fragment kodu HTML znajdujący się w sekcji `<body>`, można użyć [narzędzia Codepen](https://codepen.io/pen/). Oprócz samego HTMLa jest tam możliwość zdefiniowania stylów (wyglądu strony) w języku CSS oraz skryptów w JavaScripcie (czyli mechanizmów, które możemy zaprogramować).





---
---
---
&nbsp;
### 3.2 Podstawy działania protokołu HTTP
Protokół HTTP (ang. *HyperText Transfer Protocol*) jest standardem komunikacyjnym używanym do przesyłania danych za pośrednictwem internetu. Pozwala na komunikację między serwerem a tzw. klientem, którym może być np. przeglądarka.

HTTP służy głównie do przekazywania informacji w formie tekstowej, takiej jak strony internetowe, ale również obrazów czy plików. HTTP opiera się na modelu żądanie-odpowiedź (*request-response*), gdzie klient wysyła żądanie do serwera, a serwer odpowiada przesłaniem odpowiednich danych.

![[http.png]]

Istnieją różne rodzaje requestów, są to tzw. metody HTTP. Do najbardziej popularnych należą:
- GET - służy do pobierania danych z serwera
- POST - służy do przesyłania danych do serwera, na przykład formularzy
- PUT - służy do aktualizacji lub utworzenia zasobu na serwerze
- DELETE - służy do żądania usunięcia określonego zasobu na serwerze


Po otrzymaniu żądania, serwer wysyła odpowiedź. Składają się na nią przede wszystkim:
- kod odpowiedzi
- tekst odpowiedzi

**Kod** służy do określenia statusu odpowiedzi. Zawiera informację o tym, czy wszystko poszło po naszej mysli, czy pojawiły się jakieś błędy. Opis poszczególnych kodów można znaleźć m.in. [na wikipedii](https://pl.wikipedia.org/wiki/Kod_odpowiedzi_HTTP).

**Tekst** odpowiedzi to właściwe dane, które wysłał serwer. Może to być np. kod HTML albo dane w formacie JSON.


---
---
---
&nbsp;
### 3.3 Web scraping
Web scraping jest procesem, który polega na maszynowym pobieraniu danych znajdujących się na stronach internetowych. Polega on na wysyłaniu requestów HTTP do serwera z poziomu kodu pisanego przez programistę (zamiast w przeglądarce). W Pythonie istnieją różne frameworki do web scrapingu. Jeden z nich polega na wykorzystaniu bibliotek `requests` oraz `bs4`.

```python
import requests
from bs4 import BeautifulSoup
```

Pierwszym krokiem w procesie scrapingu jest wykonanie żądania do określonego zasobu na serwerze. Najczęściej jest to request typu GET.


```python
quotes_url = "https://quotes.toscrape.com/"

response = requests.get(quotes_url)
print(response)

# <Response [200]>
```

Funkcja `reuests.get()`  zwraca obiekt typu `requests.models.Response`. Spośród wszystkich atrybutów tego obiektu, najbardziej interesuje nas atrybut `text`, ponieważ to tam znajduje się tekst odpowiedzi. Jest nim najczęściej kod HTML, który w dalszej kolejności możemy zamienić na tzw. zupę:

```python
soup = BeautifulSoup(response.text, 'html.parser')
```

Zupa to obiekt typu `bs4.BeautifulSoup`, który pozwala w prosty sposób wyszukiwać poszczególne treści na stronie, a ściślej – w kodzie HTML.

---

Aby znaleźć pierwszy z kolei znacznik danego typu, np. `<a>`, używamy metody `find()`:

```python
soup.find("a")

# <a href="/" style="text-decoration: none">Quotes to Scrape</a>
```

Zwraca ona obiekt reprezentujacy HTMLowy tag. Gdybyśmy chcieli wyszukać wszystkie wystąpienia tego znacznika, wywołujemy metodę `find_all()`. Zwraca ona listę tagów.

```python
soup.find_all("a")

# [<a href="/" style="text-decoration: none">Quotes to Scrape</a>,
#  ..., ...]
```

---

Kolejnym krokiem jest wydobycie ze znacznika jego zawartości, czyli znajdującego się w nim tekstu. W tym celu należy odwołać się do atrybutu `text`:

```python
a_tag = soup.find("a")

a_tag.text
# Quotes to Scrape
```

---

Istnieje również możliwość doprecyzowania tego, który konkretnie znacznik nas interesuje. Tagi HTML zazwyczaj posiadają informację o tzw. klasie CSS. Klasa taka jest zbiorem reguł używanych do nadania elementowi strony konkretnego wyglądu. W procesie web scrapingu wygląd elementu (kolor, rozmiar itp.) nie ma dla nas znaczenia. Możemy jednak wykorzystać fakt, że informacja o klasie często znajduje się w znacznikach.

Tag, który odwołuje się do klasy "style" wygląda następująco:

```html
<div class='style'>Zawartość tekstowa znacznika</div>
```

Jeśli więc chcemy znaleźć w zupie takiego diva, który posiada klasę "style", należy określić to w metodzie `find()` lub `find_all()`:

```python
div_tag = soup.find("div", class_="style")

div_tag.text
# Zawartość tekstowa znacznika
```

Istnieją również inne sposoby na znalezienie tego znacznika, który nas interesuje.

Ważne jest, aby przed wywołaniem metody `find()` lub `find_all()` sprawdzić w źródle strony, w jakim znaczniku znajduje się interesująca nas treść oraz jaką posiada klasę CSS.




---
---
---
&nbsp;
### 3.4 JSON API

Nie zawsze konieczne jest scrapowanie stron, żeby pozyskać interesujace nas dane. Alternatywą jest korzystanie z tzw. API (*Application Programming Interface*) czyli interfejsu, który został stworzony w celu komunikacji z daną usługą, poprzez wysyłanie odpowiednich requestów. W przeciwieństwie do web scrapingu jednak, API nie jest czymś czego możemy użyć w każdej sytuacji, ponieważ musi ono istnieć.

Przykładowe instytucje/usługi, które wystawiają API to:
- Główny Urząd Statystyczny
- Narodowy Bank Polski
- GitHub

API mogą, ale nie muszą, służyć do pozyskiwania danych. Istnieją takie, które dostarczają np. danych pogodowych, finansowych itp. Nie jest to jednak jedyne zastosowanie API. W ogólności API mogą służyć do szeroko pojętej komunikacji między usługami z wykorzystaniem m.in. protokołu HTTP.

---

Korzystając z API najczęściej konieczne jest posiadanie specjalnego klucza, którym możemy się uwierzytelnić w usłudze. Aby go otrzymać, zwykle musimy się zarejestrować. 

Sposób korzystania z API powinien być opisany w dokumentacji. Zazwyczaj jest tam instrukcja tworzenia adresów URL, które pozwalają dostać się pod określony zasób. Poniżej znajduje się przykład użycia API *currencylayer*.

```python
api_key = "..."  # use your key
date = "2019-05-12"
currencies_list = "EUR,PLN"


url = f"http://api.currencylayer.com/historical?access_key={api_key}&date={date}&currencies={currencies_list}"

# http://api.currencylayer.com/historical?access_key=...&date=2019-05-12&currencies=EUR,PLN
```

Tak sformatowany adres URL można wykorzystać do wysłania requestu. W wielu przypadkach możemy użyć zwykłej przeglądarki, wpisując do niej adres zasobu. Jeśli jednak chcemy przechwycić i przetworzyć output, lepiej będzie napisać skrypt, który to zrobi.

```python
import requests

response = requests.get(url)
response_json = response.json()
```

Dane w formacie JSON zostały przechwycone do słownika, który możemy dalej przetwarzać. Struktura takiego słownika często jest złożona, aby mogła oddać stopień złożoności modelu danych.



---
---
---
&nbsp;
